{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cubic-mainland",
   "metadata": {
    "papermill": {
     "duration": 0.031414,
     "end_time": "2021-05-13T12:38:40.686073",
     "exception": false,
     "start_time": "2021-05-13T12:38:40.654659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hate Speech Detection - Part I: Data Gathering\n",
    "In this notebook we gather data to build a general hate speech model that predicts if a tweet conveys hate speech or not. We save the train and test splits of the generated dataset in csv files (see end of notebook).\n",
    "\n",
    "We want to train a Bertweet model. This model requires specific tweet normalization:\n",
    " - Tokenize  those  English  Tweets  using  “TweetTokenizer”  from  the  NLTK  toolkit  (Bird  et  al.,2009)\n",
    " - use the `emoji` package to translate emotion icons into text strings (here, each icon is referred to as a word token).\n",
    " - We also normalize the Tweets by converting user mentions and web/url  links  into  special  tokens `@USER` and `HTTPURL`, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-holmes",
   "metadata": {
    "papermill": {
     "duration": 0.029568,
     "end_time": "2021-05-13T12:38:40.746698",
     "exception": false,
     "start_time": "2021-05-13T12:38:40.717130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-quick",
   "metadata": {
    "papermill": {
     "duration": 0.029275,
     "end_time": "2021-05-13T12:38:40.805780",
     "exception": false,
     "start_time": "2021-05-13T12:38:40.776505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "small-footwear",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:40.870476Z",
     "iopub.status.busy": "2021-05-13T12:38:40.869266Z",
     "iopub.status.idle": "2021-05-13T12:38:42.653365Z",
     "shell.execute_reply": "2021-05-13T12:38:42.652481Z"
    },
    "papermill": {
     "duration": 1.818144,
     "end_time": "2021-05-13T12:38:42.653552",
     "exception": false,
     "start_time": "2021-05-13T12:38:40.835408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for reading csv files\n",
    "import csv\n",
    "\n",
    "# for shuffling data\n",
    "import random\n",
    "\n",
    "# for preprocessing \n",
    "import re # (finding @user for example)\n",
    "import string # (for finding printable chars)\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "import emoji\n",
    "\n",
    "# for creating csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-defensive",
   "metadata": {
    "papermill": {
     "duration": 0.02913,
     "end_time": "2021-05-13T12:38:42.713319",
     "exception": false,
     "start_time": "2021-05-13T12:38:42.684189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Collecting Data\n",
    "We will construct a dataset from two pre-existing Kaggle datasets (see “<i>Twitter Sentiment Analysis</i>” [here](https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech?select=train.csv) and “<i>Hate Speech and Offensive Language Dataset</i> [here](https://www.kaggle.com/mrmorj/hate-speech-and-offensive-language-dataset)”) of roughly 30 000 tweets each.\n",
    "<br>\n",
    "The result is a labeled (Hate / NotHate) dataset of 14 600 tweets with the following distribution [<b>NOTE</b> that if needed these distributions can be tweaked]: \n",
    "- Hate: 3 000 tweets ( ~ 20 % of the data). \n",
    "- Not Hate: 11600 tweets (~ 80 % of the data). This Not Hate subset contains:\n",
    "    - 1 500 Offensive Language tweets ( ~ 13% of Not Hate data)\n",
    "    - 10 100 “normal” tweets (~ 87% of Not Hate data).\n",
    "    \n",
    "Note that we will preprocess the data after constructing the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-christopher",
   "metadata": {
    "papermill": {
     "duration": 0.029423,
     "end_time": "2021-05-13T12:38:42.773949",
     "exception": false,
     "start_time": "2021-05-13T12:38:42.744526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. <i>Twitter Sentiment Analysis</i> Dataset\n",
    "First let's get the necessary data from this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-ottawa",
   "metadata": {
    "papermill": {
     "duration": 0.029282,
     "end_time": "2021-05-13T12:38:42.834146",
     "exception": false,
     "start_time": "2021-05-13T12:38:42.804864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.1 Read <i>Twitter Sentiment Analysis</i> Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-uncle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:42.900564Z",
     "iopub.status.busy": "2021-05-13T12:38:42.899822Z",
     "iopub.status.idle": "2021-05-13T12:38:43.182402Z",
     "shell.execute_reply": "2021-05-13T12:38:43.182904Z"
    },
    "papermill": {
     "duration": 0.319272,
     "end_time": "2021-05-13T12:38:43.183191",
     "exception": false,
     "start_time": "2021-05-13T12:38:42.863919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../input/twitter-sentiment-analysis-hatred-speech/train.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    dataset1 = [{k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-congress",
   "metadata": {
    "papermill": {
     "duration": 0.028922,
     "end_time": "2021-05-13T12:38:43.242108",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.213186",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at what this dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serial-engagement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:43.308737Z",
     "iopub.status.busy": "2021-05-13T12:38:43.307957Z",
     "iopub.status.idle": "2021-05-13T12:38:43.312239Z",
     "shell.execute_reply": "2021-05-13T12:38:43.311682Z"
    },
    "papermill": {
     "duration": 0.040944,
     "end_time": "2021-05-13T12:38:43.312384",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.271440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'label': '0',\n",
       " 'tweet': '@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-velvet",
   "metadata": {
    "papermill": {
     "duration": 0.029723,
     "end_time": "2021-05-13T12:38:43.372508",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.342785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Label 0 means Not Hate and label 1 means Hate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-greece",
   "metadata": {
    "papermill": {
     "duration": 0.029504,
     "end_time": "2021-05-13T12:38:43.431843",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.402339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.2. Gather Hate Data from <i>Twitter Sentiment Analysis</i> Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cubic-operator",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:43.495095Z",
     "iopub.status.busy": "2021-05-13T12:38:43.494467Z",
     "iopub.status.idle": "2021-05-13T12:38:43.503302Z",
     "shell.execute_reply": "2021-05-13T12:38:43.503818Z"
    },
    "papermill": {
     "duration": 0.042267,
     "end_time": "2021-05-13T12:38:43.504011",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.461744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hate_data1 = [row[\"tweet\"] for row in dataset1 if row[\"label\"] == \"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-refrigerator",
   "metadata": {
    "papermill": {
     "duration": 0.029968,
     "end_time": "2021-05-13T12:38:43.564542",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.534574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see an example of Hate speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extensive-board",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:43.629329Z",
     "iopub.status.busy": "2021-05-13T12:38:43.628135Z",
     "iopub.status.idle": "2021-05-13T12:38:43.633329Z",
     "shell.execute_reply": "2021-05-13T12:38:43.633782Z"
    },
    "papermill": {
     "duration": 0.039162,
     "end_time": "2021-05-13T12:38:43.633960",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.594798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@user why not @user mocked obama for being black.  @user @user @user @user #brexit'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_data1[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-programming",
   "metadata": {
    "papermill": {
     "duration": 0.030387,
     "end_time": "2021-05-13T12:38:43.695676",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.665289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's also see how much hate speech data we've got from this data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spare-convenience",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:43.776969Z",
     "iopub.status.busy": "2021-05-13T12:38:43.775987Z",
     "iopub.status.idle": "2021-05-13T12:38:43.782305Z",
     "shell.execute_reply": "2021-05-13T12:38:43.781647Z"
    },
    "papermill": {
     "duration": 0.047109,
     "end_time": "2021-05-13T12:38:43.782452",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.735343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-palace",
   "metadata": {
    "papermill": {
     "duration": 0.03723,
     "end_time": "2021-05-13T12:38:43.851414",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.814184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1.3. Gather Non-Hate Data from <i>Twitter Sentiment Analysis</i> Data set\n",
    "We only want to keep 5000 examples of Non-Hate speech from this dataset (the rest will be from the other dataset to keep things balanced)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "level-booth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:43.919283Z",
     "iopub.status.busy": "2021-05-13T12:38:43.918195Z",
     "iopub.status.idle": "2021-05-13T12:38:43.930063Z",
     "shell.execute_reply": "2021-05-13T12:38:43.930832Z"
    },
    "papermill": {
     "duration": 0.047113,
     "end_time": "2021-05-13T12:38:43.931091",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.883978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonhate_data1 = [row[\"tweet\"] for row in dataset1 if row[\"label\"] == \"0\"][:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-daisy",
   "metadata": {
    "papermill": {
     "duration": 0.038881,
     "end_time": "2021-05-13T12:38:44.007559",
     "exception": false,
     "start_time": "2021-05-13T12:38:43.968678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. <i>Hate Speech and Offensive Language Dataset</i> Dataset\n",
    "Now let's get the necessary data from this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-edmonton",
   "metadata": {
    "papermill": {
     "duration": 0.031862,
     "end_time": "2021-05-13T12:38:44.073561",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.041699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.1. Read <i>Hate Speech and Offensive Language Dataset</i> Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quick-resort",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:44.141479Z",
     "iopub.status.busy": "2021-05-13T12:38:44.140776Z",
     "iopub.status.idle": "2021-05-13T12:38:44.395830Z",
     "shell.execute_reply": "2021-05-13T12:38:44.394981Z"
    },
    "papermill": {
     "duration": 0.291281,
     "end_time": "2021-05-13T12:38:44.395989",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.104708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../input/hate-speech-and-offensive-language-dataset/labeled_data.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    dataset2 = [{k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-belief",
   "metadata": {
    "papermill": {
     "duration": 0.038116,
     "end_time": "2021-05-13T12:38:44.466628",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.428512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look to see what this dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "listed-apartment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:44.532836Z",
     "iopub.status.busy": "2021-05-13T12:38:44.531865Z",
     "iopub.status.idle": "2021-05-13T12:38:44.537540Z",
     "shell.execute_reply": "2021-05-13T12:38:44.538147Z"
    },
    "papermill": {
     "duration": 0.040668,
     "end_time": "2021-05-13T12:38:44.538334",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.497666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': '0',\n",
       " 'count': '3',\n",
       " 'hate_speech': '0',\n",
       " 'offensive_language': '0',\n",
       " 'neither': '3',\n",
       " 'class': '2',\n",
       " 'tweet': \"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-innocent",
   "metadata": {
    "papermill": {
     "duration": 0.031457,
     "end_time": "2021-05-13T12:38:44.601376",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.569919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Class 0: hate speech \n",
    "- Class 1: offensive language\n",
    "- Class 2: \"neither"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-scholar",
   "metadata": {
    "papermill": {
     "duration": 0.031428,
     "end_time": "2021-05-13T12:38:44.664346",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.632918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.2. Gather Hate Data from <i>Hate Speech and Offensive Language Dataset</i> Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-samoa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:44.731799Z",
     "iopub.status.busy": "2021-05-13T12:38:44.730775Z",
     "iopub.status.idle": "2021-05-13T12:38:44.738860Z",
     "shell.execute_reply": "2021-05-13T12:38:44.739376Z"
    },
    "papermill": {
     "duration": 0.043562,
     "end_time": "2021-05-13T12:38:44.739568",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.696006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hate_data2 = [row[\"tweet\"] for row in dataset2 if row[\"class\"] == \"0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-claim",
   "metadata": {
    "papermill": {
     "duration": 0.031492,
     "end_time": "2021-05-13T12:38:44.803151",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.771659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see how much hate speech data we get from this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hungry-equation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:44.870741Z",
     "iopub.status.busy": "2021-05-13T12:38:44.869740Z",
     "iopub.status.idle": "2021-05-13T12:38:44.876303Z",
     "shell.execute_reply": "2021-05-13T12:38:44.875618Z"
    },
    "papermill": {
     "duration": 0.041545,
     "end_time": "2021-05-13T12:38:44.876447",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.834902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-conditioning",
   "metadata": {
    "papermill": {
     "duration": 0.032358,
     "end_time": "2021-05-13T12:38:44.942900",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.910542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2.3. Gather Non-Hate Data from <i>Hate Speech and Offensive Language Dataset</i> Data set\n",
    "Unlike for first dataset, here we'll take some offensive language data and \"normal\" data to construct the Non Hate subset for this dataset. We add offensive language to our set to try to teach the model that being offensive doesn’t always translate to hate.\n",
    "Like said previously we want 1500 offensive language tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "artistic-angle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:45.022662Z",
     "iopub.status.busy": "2021-05-13T12:38:45.021897Z",
     "iopub.status.idle": "2021-05-13T12:38:45.025307Z",
     "shell.execute_reply": "2021-05-13T12:38:45.024626Z"
    },
    "papermill": {
     "duration": 0.050203,
     "end_time": "2021-05-13T12:38:45.025472",
     "exception": false,
     "start_time": "2021-05-13T12:38:44.975269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "offensive_data2 = [row[\"tweet\"] for row in dataset2 if row[\"class\"] == \"1\"][:1500]\n",
    "normal_data2 = [row[\"tweet\"] for row in dataset2 if row[\"class\"] == \"2\"][:4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-parallel",
   "metadata": {
    "papermill": {
     "duration": 0.034349,
     "end_time": "2021-05-13T12:38:45.092170",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.057821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we can combine these to get all Non-Hate Data for dataset 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blessed-gather",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:45.162836Z",
     "iopub.status.busy": "2021-05-13T12:38:45.162164Z",
     "iopub.status.idle": "2021-05-13T12:38:45.165732Z",
     "shell.execute_reply": "2021-05-13T12:38:45.165210Z"
    },
    "papermill": {
     "duration": 0.041108,
     "end_time": "2021-05-13T12:38:45.165877",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.124769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonhate_data2 = offensive_data2 + normal_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-excuse",
   "metadata": {
    "papermill": {
     "duration": 0.032421,
     "end_time": "2021-05-13T12:38:45.231589",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.199168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Combine both Datasets\n",
    "Now we've got Hate and Non-Hate speech from both datasets we can contruct our final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-retro",
   "metadata": {
    "papermill": {
     "duration": 0.033127,
     "end_time": "2021-05-13T12:38:45.297646",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.264519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3.1 Concatenate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flying-congress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:45.379295Z",
     "iopub.status.busy": "2021-05-13T12:38:45.378572Z",
     "iopub.status.idle": "2021-05-13T12:38:45.382264Z",
     "shell.execute_reply": "2021-05-13T12:38:45.381720Z"
    },
    "papermill": {
     "duration": 0.051925,
     "end_time": "2021-05-13T12:38:45.382435",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.330510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialise final dataset\n",
    "data = []\n",
    "\n",
    "# concatenate all hate data\n",
    "hate_data = hate_data1 + hate_data2\n",
    "\n",
    "# concatenate all non-hate data\n",
    "nonhate_data = nonhate_data1 + nonhate_data2\n",
    "\n",
    "# add hate data to final dataset\n",
    "for row in hate_data:\n",
    "    data.append({\"label\": 1, \"tweet\": row})\n",
    "    \n",
    "# add non-hate data to final dataset\n",
    "for row in nonhate_data:\n",
    "    data.append({\"label\": 0, \"tweet\": row})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-loading",
   "metadata": {
    "papermill": {
     "duration": 0.032763,
     "end_time": "2021-05-13T12:38:45.448570",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.415807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3.2. Shuffle data\n",
    "We don't want for example all hatespeech data to be together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifty-romance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:45.535720Z",
     "iopub.status.busy": "2021-05-13T12:38:45.535049Z",
     "iopub.status.idle": "2021-05-13T12:38:45.538663Z",
     "shell.execute_reply": "2021-05-13T12:38:45.538037Z"
    },
    "papermill": {
     "duration": 0.057002,
     "end_time": "2021-05-13T12:38:45.538816",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.481814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-tongue",
   "metadata": {
    "papermill": {
     "duration": 0.032754,
     "end_time": "2021-05-13T12:38:45.606429",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.573675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally let's see what our final dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "careful-enlargement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:45.679560Z",
     "iopub.status.busy": "2021-05-13T12:38:45.678527Z",
     "iopub.status.idle": "2021-05-13T12:38:45.683772Z",
     "shell.execute_reply": "2021-05-13T12:38:45.684304Z"
    },
    "papermill": {
     "duration": 0.045019,
     "end_time": "2021-05-13T12:38:45.684485",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.639466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 0,\n",
       "  'tweet': \"&#8220;@Benkasso: I'll beat the pussy up, that's a hook right thur&#8221; &#128064;\"},\n",
       " {'label': 1,\n",
       "  'tweet': \"Michael Sam being cut further proves that we fags don't belong in football or #NFL, it is a heterosexual sport for heterosexuals.\"},\n",
       " {'label': 0,\n",
       "  'tweet': 'why #men get   - #emotions #masculinity #progressive #religion '},\n",
       " {'label': 0,\n",
       "  'tweet': 'felt good to get to a meeting tonight! #aa #recovery #sobriety #grateful #sober   #blessed'},\n",
       " {'label': 1,\n",
       "  'tweet': \"here's what ignorance &amp;  looks like. it ain't all swastikas &amp; burning crosses... \"},\n",
       " {'label': 1, 'tweet': 'dull british . '},\n",
       " {'label': 0,\n",
       "  'tweet': 'happy bihday my gorgeous thing! today is all about you so soak it up you superstar!  â\\x80¦ '},\n",
       " {'label': 0,\n",
       "  'tweet': '#decors   buffalo simulation: buffalo for you to take in the vicinity of their homes to do. in this way, you '},\n",
       " {'label': 0,\n",
       "  'tweet': 'RT @OnionSports: Yankees Unveil Beautiful Derek Jeter Cage In Monument Park http://t.co/vv6urct4jd http://t.co/gWBNHDyhMl'},\n",
       " {'label': 1,\n",
       "  'tweet': '@user #allahsoil culture is like the horizonâ\\x80\\x95always in view but never in reach.  â\\x80¦  â\\x80¦ '}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-organ",
   "metadata": {
    "papermill": {
     "duration": 0.034931,
     "end_time": "2021-05-13T12:38:45.753178",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.718247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Preprocessing Data\n",
    "Some tweets are messy (see previous output for examples). We need to clean up this mess as much as possible. For this we fine a function `clean_tweet` that removes links, retweets (RT), mentions (@) and unprintable characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-option",
   "metadata": {
    "papermill": {
     "duration": 0.033374,
     "end_time": "2021-05-13T12:38:45.820078",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.786704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1. `clean_tweet` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "collective-sheffield",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:45.895869Z",
     "iopub.status.busy": "2021-05-13T12:38:45.894833Z",
     "iopub.status.idle": "2021-05-13T12:38:45.897934Z",
     "shell.execute_reply": "2021-05-13T12:38:45.898432Z"
    },
    "papermill": {
     "duration": 0.045179,
     "end_time": "2021-05-13T12:38:45.898614",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.853435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    # tokenize tweet\n",
    "    tokenized_tweet = \" \".join(tokenizer.tokenize(tweet))\n",
    "\n",
    "    # remove unprintable characters (ð\\x9f\\x98\\x81ð\\x9f\\x98\\x81 for ex)\n",
    "    printable_tweet = ''.join(filter(lambda x: x in set(string.printable), tokenized_tweet))\n",
    "    \n",
    "    # replace links (https://www. for ex) HTTPURL\n",
    "    linkless_tweet = re.sub(r\"http\\S+\", \"HTTPURL\", printable_tweet)\n",
    "    \n",
    "    # remove retweets (RT)\n",
    "    retweetless_tweet = re.sub(r\"RT\", \"\", linkless_tweet)\n",
    "    \n",
    "    # replace mentions (@user for example) with @USER\n",
    "    mentionless_tweet = re.sub(r\"@[\\S]+\", \"@USER\", retweetless_tweet)\n",
    "    \n",
    "    # remove other odd stuff (&... for ex)\n",
    "    other = re.sub(r\"&[\\S]+\", \"\", mentionless_tweet)\n",
    "    \n",
    "    # replace emojis with str\n",
    "    emojiless_tweet = emoji.demojize(other)\n",
    "    \n",
    "    # remove unwanted whitespace (ex \"Hello        XWorld\" => \"hell world\")\n",
    "    whitespaceless = re.sub(r'\\s+', ' ', emojiless_tweet)\n",
    "    \n",
    "    return whitespaceless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-drinking",
   "metadata": {
    "papermill": {
     "duration": 0.034278,
     "end_time": "2021-05-13T12:38:45.966493",
     "exception": false,
     "start_time": "2021-05-13T12:38:45.932215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stunning-terminal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:46.048407Z",
     "iopub.status.busy": "2021-05-13T12:38:46.043199Z",
     "iopub.status.idle": "2021-05-13T12:38:46.247774Z",
     "shell.execute_reply": "2021-05-13T12:38:46.247218Z"
    },
    "papermill": {
     "duration": 0.247256,
     "end_time": "2021-05-13T12:38:46.247914",
     "exception": false,
     "start_time": "2021-05-13T12:38:46.000658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@USER is that the name of any upcoming new track ? #2pm #kpop HTTPURL'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet(\"@user is that the name of any upcoming new track? ð\\x9f\\x98\\x81ð\\x9f\\x98\\x81 #2pm #kpop https:www.google.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-cross",
   "metadata": {
    "papermill": {
     "duration": 0.03415,
     "end_time": "2021-05-13T12:38:46.316581",
     "exception": false,
     "start_time": "2021-05-13T12:38:46.282431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Clean all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sustainable-church",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:46.409570Z",
     "iopub.status.busy": "2021-05-13T12:38:46.398817Z",
     "iopub.status.idle": "2021-05-13T12:38:56.342689Z",
     "shell.execute_reply": "2021-05-13T12:38:56.343201Z"
    },
    "papermill": {
     "duration": 9.992339,
     "end_time": "2021-05-13T12:38:56.343392",
     "exception": false,
     "start_time": "2021-05-13T12:38:46.351053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 0,\n",
       "  'tweet': \" @USER : I'll beat the pussy up , that's a hook right thur \"},\n",
       " {'label': 1,\n",
       "  'tweet': \"Michael Sam being cut further proves that we fags don't belong in football or #NFL , it is a heterosexual sport for heterosexuals .\"},\n",
       " {'label': 0,\n",
       "  'tweet': 'why #men get - #emotions #masculinity #progressive #religion'},\n",
       " {'label': 0,\n",
       "  'tweet': 'felt good to get to a meeting tonight ! #aa #recovery #sobriety #grateful #sober #blessed'},\n",
       " {'label': 1,\n",
       "  'tweet': \"here's what ignorance & looks like . it ain't all swastikas & burning crosses ...\"},\n",
       " {'label': 1, 'tweet': 'dull british .'},\n",
       " {'label': 0,\n",
       "  'tweet': 'happy bihday my gorgeous thing ! today is all about you so soak it up you superstar ! '},\n",
       " {'label': 0,\n",
       "  'tweet': '#decors buffalo simulation : buffalo for you to take in the vicinity of their homes to do . in this way , you'},\n",
       " {'label': 0,\n",
       "  'tweet': ' @USER : Yankees Unveil Beautiful Derek Jeter Cage In Monument Park HTTPURL HTTPURL'},\n",
       " {'label': 1,\n",
       "  'tweet': '@USER #allahsoil culture is like the horizon always in view but never in reach . '}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = [{\"label\": row[\"label\"], \"tweet\": clean_tweet(row[\"tweet\"])} for row in data]\n",
    "clean_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-special",
   "metadata": {
    "papermill": {
     "duration": 0.034298,
     "end_time": "2021-05-13T12:38:56.412345",
     "exception": false,
     "start_time": "2021-05-13T12:38:56.378047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Splitting Data\n",
    "Now we want to split our data into train and test splits. We will go for <b>15% test</b> and <b>85% train/dev</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "saving-formula",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:56.495112Z",
     "iopub.status.busy": "2021-05-13T12:38:56.493388Z",
     "iopub.status.idle": "2021-05-13T12:38:56.498373Z",
     "shell.execute_reply": "2021-05-13T12:38:56.497725Z"
    },
    "papermill": {
     "duration": 0.051742,
     "end_time": "2021-05-13T12:38:56.498525",
     "exception": false,
     "start_time": "2021-05-13T12:38:56.446783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(clean_data, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-sleep",
   "metadata": {
    "papermill": {
     "duration": 0.034745,
     "end_time": "2021-05-13T12:38:56.568166",
     "exception": false,
     "start_time": "2021-05-13T12:38:56.533421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Save Data to csv for further use.\n",
    "Store train and test splits in csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chemical-copper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:56.654097Z",
     "iopub.status.busy": "2021-05-13T12:38:56.653356Z",
     "iopub.status.idle": "2021-05-13T12:38:56.754558Z",
     "shell.execute_reply": "2021-05-13T12:38:56.753977Z"
    },
    "papermill": {
     "duration": 0.151768,
     "end_time": "2021-05-13T12:38:56.754715",
     "exception": false,
     "start_time": "2021-05-13T12:38:56.602947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert the lists of dictionaries to pandas DataFrames\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# convert to csv\n",
    "train_df.to_csv(\"hatespeech_train.csv\", index = False)\n",
    "test_df.to_csv(\"hatespeech_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-clinton",
   "metadata": {
    "papermill": {
     "duration": 0.034846,
     "end_time": "2021-05-13T12:38:56.825072",
     "exception": false,
     "start_time": "2021-05-13T12:38:56.790226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check the content of these csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "studied-drawing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T12:38:56.918797Z",
     "iopub.status.busy": "2021-05-13T12:38:56.900792Z",
     "iopub.status.idle": "2021-05-13T12:38:57.645012Z",
     "shell.execute_reply": "2021-05-13T12:38:57.644308Z"
    },
    "papermill": {
     "duration": 0.783968,
     "end_time": "2021-05-13T12:38:57.645206",
     "exception": false,
     "start_time": "2021-05-13T12:38:56.861238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label,tweet\r\n",
      "1,@USER here comes a #supermistict douchebag who can only poke his nose as sme of all . #burninhell\r\n",
      "0,\"\"\" my father gave me the greatest gift anyone could give another person - he believed in me \"\" #fathersday to all the dads out there \"\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 hatespeech_test.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.831227,
   "end_time": "2021-05-13T12:38:58.593251",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-13T12:38:31.762024",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
